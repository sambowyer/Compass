
@misc{aitchison_tensor_2019,
	title = {Tensor {Monte} {Carlo}: particle methods for the {GPU} era},
	shorttitle = {Tensor {Monte} {Carlo}},
	url = {http://arxiv.org/abs/1806.08593},
	abstract = {Multi-sample, importance-weighted variational autoencoders (IWAE) give tighter bounds and more accurate uncertainty estimates than variational autoencoders (VAE) trained with a standard single-sample objective. However, IWAEs scale poorly: as the latent dimensionality grows, they require exponentially many samples to retain the beneﬁts of importance weighting. While sequential Monte-Carlo (SMC) can address this problem, it is prohibitively slow because the resampling step imposes sequential structure which cannot be parallelised, and moreover, resampling is nondifferentiable which is problematic when learning approximate posteriors. To address these issues, we developed tensor Monte-Carlo (TMC) which gives exponentially many importance samples by separately drawing K samples for each of the n latent variables, then averaging over all Kn possible combinations. While the sum over exponentially many terms might seem to be intractable, in many cases it can be computed efﬁciently as a series of tensor inner-products. We show that TMC is superior to IWAE on a generative model with multiple stochastic layers trained on the MNIST handwritten digit database, and we show that TMC can be combined with standard variance reduction techniques.},
	language = {en},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Aitchison, Laurence},
	month = jan,
	year = {2019},
	note = {arXiv:1806.08593 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Aitchison - 2019 - Tensor Monte Carlo particle methods for the GPU e.pdf:/home/dg22309/Zotero/storage/CARLCZ3Q/Aitchison - 2019 - Tensor Monte Carlo particle methods for the GPU e.pdf:application/pdf},
}

@article{chatterjee_sample_2018,
	title = {The sample size required in importance sampling},
	volume = {28},
	issn = {1050-5164},
	url = {https://projecteuclid.org/journals/annals-of-applied-probability/volume-28/issue-2/The-sample-size-required-in-importance-sampling/10.1214/17-AAP1326.full},
	doi = {10.1214/17-AAP1326},
	language = {en},
	number = {2},
	urldate = {2023-02-03},
	journal = {The Annals of Applied Probability},
	author = {Chatterjee, Sourav and Diaconis, Persi},
	month = apr,
	year = {2018},
	file = {Chatterjee and Diaconis - 2018 - The sample size required in importance sampling.pdf:/home/dg22309/Zotero/storage/PPZTY3I3/Chatterjee and Diaconis - 2018 - The sample size required in importance sampling.pdf:application/pdf},
}

@article{calderhead_general_2014,
	title = {A general construction for parallelizing {Metropolis}−{Hastings} algorithms},
	volume = {111},
	url = {https://www.pnas.org/doi/10.1073/pnas.1408184111},
	doi = {10.1073/pnas.1408184111},
	abstract = {Markov chain Monte Carlo methods (MCMC) are essential tools for solving many modern-day statistical and computational problems; however, a major limitation is the inherently sequential nature of these algorithms. In this paper, we propose a natural generalization of the Metropolis−Hastings algorithm that allows for parallelizing a single chain using existing MCMC methods. We do so by proposing multiple points in parallel, then constructing and sampling from a finite-state Markov chain on the proposed points such that the overall procedure has the correct target density as its stationary distribution. Our approach is generally applicable and straightforward to implement. We demonstrate how this construction may be used to greatly increase the computational speed and statistical efficiency of a variety of existing MCMC methods, including Metropolis-Adjusted Langevin Algorithms and Adaptive MCMC. Furthermore, we show how it allows for a principled way of using every integration step within Hamiltonian Monte Carlo methods; our approach increases robustness to the choice of algorithmic parameters and results in increased accuracy of Monte Carlo estimates with little extra computational cost.},
	number = {49},
	urldate = {2023-02-03},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Calderhead, Ben},
	month = dec,
	year = {2014},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {17408--17413},
	file = {Full Text PDF:/home/dg22309/Zotero/storage/22E26SWH/Calderhead - 2014 - A general construction for parallelizing Metropoli.pdf:application/pdf},
}

@article{metropolis_equation_1953,
	title = {Equation of {State} {Calculations} by {Fast} {Computing} {Machines}},
	volume = {21},
	issn = {0021-9606, 1089-7690},
	url = {http://aip.scitation.org/doi/10.1063/1.1699114},
	doi = {10.1063/1.1699114},
	language = {en},
	number = {6},
	urldate = {2023-02-03},
	journal = {The Journal of Chemical Physics},
	author = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
	month = jun,
	year = {1953},
	pages = {1087--1092},
	file = {Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing M.pdf:/home/dg22309/Zotero/storage/UITYPMXQ/Metropolis et al. - 1953 - Equation of State Calculations by Fast Computing M.pdf:application/pdf},
}

@article{hastings_monte_1970,
	title = {Monte {Carlo} {Sampling} {Methods} {Using} {Markov} {Chains} and {Their} {Applications}},
	abstract = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
	language = {en},
	author = {Hastings, W K},
	year = {1970},
	file = {Hastings - 2023 - Monte Carlo Sampling Methods Using Markov Chains a.pdf:/home/dg22309/Zotero/storage/F2DEIDLR/Hastings - 2023 - Monte Carlo Sampling Methods Using Markov Chains a.pdf:application/pdf},
}

@misc{burda_importance_2016,
	title = {Importance {Weighted} {Autoencoders}},
	url = {http://arxiv.org/abs/1509.00519},
	abstract = {The variational autoencoder (VAE; Kingma \& Welling (2014)) is a recently proposed generative model pairing a top-down generative network with a bottom-up recognition network which approximates posterior inference. It typically makes strong assumptions about posterior inference, for instance that the posterior distribution is approximately factorial, and that its parameters can be approximated with nonlinear regression from the observations. As we show empirically, the VAE objective can lead to overly simpliﬁed representations which fail to use the network’s entire modeling capacity. We present the importance weighted autoencoder (IWAE), a generative model with the same architecture as the VAE, but which uses a strictly tighter log-likelihood lower bound derived from importance weighting. In the IWAE, the recognition network uses multiple samples to approximate the posterior, giving it increased ﬂexibility to model complex posteriors which do not ﬁt the VAE modeling assumptions. We show empirically that IWAEs learn richer latent space representations than VAEs, leading to improved test log-likelihood on density estimation benchmarks.},
	language = {en},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
	month = nov,
	year = {2016},
	note = {arXiv:1509.00519 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Submitted to ICLR 2015},
	file = {Burda et al. - 2016 - Importance Weighted Autoencoders.pdf:/home/dg22309/Zotero/storage/L3EUWURL/Burda et al. - 2016 - Importance Weighted Autoencoders.pdf:application/pdf},
}

@misc{bornschein_reweighted_2015,
	title = {Reweighted {Wake}-{Sleep}},
	url = {http://arxiv.org/abs/1406.2751},
	abstract = {Training deep directed graphical models with many hidden variables and performing inference remains a major challenge. Helmholtz machines and deep belief networks are such models, and the wake-sleep algorithm has been proposed to train them. The wake-sleep algorithm relies on training not just the directed generative model but also a conditional generative model (the inference network) that runs backward from visible to latent, estimating the posterior distribution of latent given visible. We propose a novel interpretation of the wake-sleep algorithm which suggests that better estimators of the gradient can be obtained by sampling latent variables multiple times from the inference network. This view is based on importance sampling as an estimator of the likelihood, with the approximate inference network as a proposal distribution. This interpretation is conﬁrmed experimentally, showing that better likelihood can be achieved with this reweighted wake-sleep procedure. Based on this interpretation, we propose that a sigmoidal belief network is not sufﬁciently powerful for the layers of the inference network in order to recover a good estimator of the posterior distribution of latent variables. Our experiments show that using a more powerful layer model, such as NADE, yields substantially better generative models.},
	language = {en},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Bornschein, Jörg and Bengio, Yoshua},
	month = apr,
	year = {2015},
	note = {arXiv:1406.2751 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Bornschein and Bengio - 2015 - Reweighted Wake-Sleep.pdf:/home/dg22309/Zotero/storage/Y85L7Q53/Bornschein and Bengio - 2015 - Reweighted Wake-Sleep.pdf:application/pdf},
}

@inproceedings{ge_turing_2018,
	title = {Turing: {A} {Language} for {Flexible} {Probabilistic} {Inference}},
	shorttitle = {Turing},
	url = {https://proceedings.mlr.press/v84/ge18b.html},
	abstract = {Probabilistic programming promises to simplify and democratize probabilistic machine learning, but successful probabilistic programming systems require flexible, generic and efficient inference engines. In this work, we present a system called Turing for building MCMC algorithms for probabilistic programming inference. Turing has a very simple syntax and makes full use of the numerical capabilities in the Julia programming language, including all implemented probability distributions, and automatic differentiation. Turing supports a wide range of popular Monte Carlo algorithms, including Hamiltonian Monte Carlo (HMC), HMC with No-U-Turns (NUTS), Gibbs sampling, sequential Monte Carlo (SMC), and several particle MCMC (PMCMC) samplers. Most importantly, Turing inference is composable: it combines MCMC operations on subsets of variables, for example using a combination of an HMC engine and a particle Gibbs (PG) engine.  We explore several combinations of inference methods with the aim of finding approaches that are both efficient and universal, i.e. applicable to arbitrary probabilistic models. NUTS—a popular variant of HMC that adapts Hamiltonian simulation path length automatically, although quite powerful for exploring differentiable target distributions, is however not universal. We identify some failure modes for the NUTS engine, and demonstrate that composition of PG (for discrete variables) and NUTS (for continuous variables) can be useful when the NUTS engine is either not applicable, or simply does not work well. Our aim is to present Turing and its composable inference engines to the world and encourage other researchers to build on this system to help advance the field of probabilistic machine learning.},
	language = {en},
	urldate = {2023-02-03},
	booktitle = {Proceedings of the {Twenty}-{First} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Ge, Hong and Xu, Kai and Ghahramani, Zoubin},
	month = mar,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {1682--1690},
	file = {Full Text PDF:/home/dg22309/Zotero/storage/GAPLI7EX/Ge et al. - 2018 - Turing A Language for Flexible Probabilistic Infe.pdf:application/pdf},
}

@article{carpenter_stan_2017,
	title = {Stan: {A} probabilistic programming language},
	volume = {76},
	number = {1},
	journal = {Journal of statistical software},
	author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
	year = {2017},
	note = {Publisher: Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA (United States)},
}

@misc{kingma_auto-encoding_2014,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	doi = {10.48550/arXiv.1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2023-02-03},
	publisher = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	year = {2014},
	note = {arXiv:1312.6114 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Fixes a typo in the abstract, no other changes},
	file = {arXiv Fulltext PDF:/home/dg22309/Zotero/storage/425PKUFX/Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf:application/pdf;arXiv.org Snapshot:/home/dg22309/Zotero/storage/FG5HQUKF/1312.html:text/html},
}

@incollection{jordan_introduction_1998,
	address = {Dordrecht},
	title = {An {Introduction} to {Variational} {Methods} for {Graphical} {Models}},
	isbn = {978-94-010-6104-9 978-94-011-5014-9},
	url = {http://link.springer.com/10.1007/978-94-011-5014-9_5},
	abstract = {This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random ﬁelds). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simpliﬁed graphical model in which inference is efﬁcient. Inference in the simpiﬁed model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.},
	language = {en},
	urldate = {2023-02-03},
	booktitle = {Learning in {Graphical} {Models}},
	publisher = {Springer Netherlands},
	author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
	editor = {Jordan, Michael I.},
	year = {1998},
	doi = {10.1007/978-94-011-5014-9_5},
	pages = {105--161},
	file = {Jordan et al. - 1998 - An Introduction to Variational Methods for Graphic.pdf:/home/dg22309/Zotero/storage/W7VYJSC4/Jordan et al. - 1998 - An Introduction to Variational Methods for Graphic.pdf:application/pdf},
}

@article{hinton_wake-sleep_1995,
	title = {The "{Wake}-{Sleep}" {Algorithm} for {Unsupervised} {Neural} {Networks}},
	volume = {268},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.7761831},
	doi = {10.1126/science.7761831},
	abstract = {An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up "recognition" connections convert the input into representations in successive hidden layers, and top-down "generative" connections reconstruct the representation in one layer from the representation in the layer above. In the "wake" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the "sleep" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above.},
	language = {en},
	number = {5214},
	urldate = {2023-02-03},
	journal = {Science},
	author = {Hinton, Geoffrey E. and Dayan, Peter and Frey, Brendan J. and Neal, Radford M.},
	month = may,
	year = {1995},
	pages = {1158--1161},
	annote = {[TLDR] An unsupervised learning algorithm for a multilayer network of stochastic neurons is described, where bottom-up "recognition" connections convert the input into representations in successive hidden layers, and top-down "generative" connections reconstruct the representation in one layer from the representations in the layer above.},
}

@article{mousavi_hamiltonian_2021,
	title = {Hamiltonian {Adaptive} {Importance} {Sampling}},
	volume = {28},
	issn = {1070-9908, 1558-2361},
	url = {http://arxiv.org/abs/2209.13716},
	doi = {10.1109/LSP.2021.3068616},
	abstract = {Importance sampling (IS) is a powerful Monte Carlo (MC) methodology for approximating integrals, for instance in the context of Bayesian inference. In IS, the samples are simulated from the so-called proposal distribution, and the choice of this proposal is key for achieving a high performance. In adaptive IS (AIS) methods, a set of proposals is iteratively improved. AIS is a relevant and timely methodology although many limitations remain yet to be overcome, e.g., the curse of dimensionality in high-dimensional and multi-modal problems. Moreover, the Hamiltonian Monte Carlo (HMC) algorithm has become increasingly popular in machine learning and statistics. HMC has several appealing features such as its exploratory behavior, especially in high-dimensional targets, when other methods suffer. In this paper, we introduce the novel Hamiltonian adaptive importance sampling (HAIS) method. HAIS implements a two-step adaptive process with parallel HMC chains that cooperate at each iteration. The proposed HAIS efﬁciently adapts a population of proposals, extracting the advantages of HMC. HAIS can be understood as a particular instance of the generic layered AIS family with an additional resampling step. HAIS achieves a signiﬁcant performance improvement in high-dimensional problems w.r.t. state-of-the-art algorithms. We discuss the statistical properties of HAIS and show its high performance in two challenging examples.},
	language = {en},
	urldate = {2023-02-03},
	journal = {IEEE Signal Processing Letters},
	author = {Mousavi, Ali and Monsefi, Reza and Elvira, Víctor},
	year = {2021},
	note = {arXiv:2209.13716 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {713--717},
	file = {Mousavi et al. - 2021 - Hamiltonian Adaptive Importance Sampling.pdf:/home/dg22309/Zotero/storage/TUVXSBKG/Mousavi et al. - 2021 - Hamiltonian Adaptive Importance Sampling.pdf:application/pdf},
}
